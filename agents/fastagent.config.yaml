# FastAgent Configuration File

# Default Model Configuration:
#
# Takes format:
#   <provider>.<model_string>.<reasoning_effort?> (e.g. anthropic.claude-3-5-sonnet-20241022 or openai.o3-mini.low)
# Accepts aliases for Anthropic Models: haiku, haiku3, sonnet, sonnet35, opus, opus3
# and OpenAI Models: gpt-4.1, gpt-4.1-mini, o1, o1-mini, o3-mini
#
# If not specified, defaults to "gpt-5-mini.low".
# Can be overriden with a command line switch --model=<model>, or within the Agent constructor.

default_model: google.gemini-2.5-flash
# mcp-ui support: disabled, enabled or auto. "auto" opens the web browser on the asset automatically
# mcp_ui_output_dir: ".fast-agent/ui"  # Where to write MCP-UI HTML files (relative to CWD if not absolute)
# mcp_ui_mode: enabled

# otel:
#   enabled: true

# Logging and Console Configuration:
logger:
    # level: "debug" | "info" | "warning" | "error"
    # type: "none" | "console" | "file" | "http"
    # path: "/path/to/logfile.jsonl"

    # Switch the progress display on or off
    progress_display: true

    # Show chat User/Assistant messages on the console
    show_chat: true
    # Show tool calls on the console
    show_tools: true
    # Truncate long tool responses on the console
    truncate_tools: true

    streaming: markdown

# agent와 mcp server 연결
# servers 하위의 server 이름은 agent.py에서 @fast.agent의 servers 안에 포함되어야합니다.

# MCP Servers
mcp:
    servers:
        fetch:
            command: "uvx"
            args: ["mcp-server-fetch"]
        filesystem:
            command: "npx"
            args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
        huggingface:
            url: "https://huggingface.co/mcp?login"
        duckduckgo:
            command: "uvx"
            args: ["ddg-mcp-server"]
        mcp-mock-server:
            transport: http
            url: http://127.0.0.1:9092/mcp
            implementation:
                name: mcp-mock-server
                version: 1.0.0
